python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_10b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 10 --bias-precision 10 --act-precision 13  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_10b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_11b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 11 --bias-precision 11 --act-precision 14  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_11b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_32b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 32 --bias-precision 32 --act-precision 35  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_32b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_6b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 6 --bias-precision 6 --act-precision 9  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_6b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_7b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 7 --bias-precision 7 --act-precision 10  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_7b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_8b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 8 --bias-precision 8 --act-precision 11  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_8b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.1 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.1/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.05 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.05/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.025 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.025/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0125/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.00625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.00625/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.003125 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.003125/normal/ECON_9b/err_small_4.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/ --file-prefix exp_0 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/log_small_0.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/err_small_0.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/ --file-prefix exp_1 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/log_small_1.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/err_small_1.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/ --file-prefix exp_2 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/log_small_2.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/err_small_2.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/ --file-prefix exp_3 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/log_small_3.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/err_small_3.txt >&2) 
python code/train.py --training-type normal --experiment_name small --arch ECON_9b --saving-folder ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/ --file-prefix exp_4 --mixup-alpha 16.0 --data-subset --subset 1.0 --data_dir ../../data/ECON/Elegun  --lr 0.0015625 --weight-decay 0.0005 --train-bs 500 --test-bs 500 --weight-precision 9 --bias-precision 9 --act-precision 12  --no-lr-decay --max_epochs 25 --save-early-stop --min-delta 0.0001 --patience 5 --save-best --train --ignore-incomplete-batch > >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/log_small_4.txt) 2> >(tee -a ../checkpoint/different_knobs_subset_10/lr_0.0015625/normal/ECON_9b/err_small_4.txt >&2) 
