train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weightprecision 10
biasprecision 10
actprecision 13
batch-norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weightprecision 10
biasprecision 10
actprecision 13
batch-norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/train/jetImage_2_100p_20000_30000.h5
Could not load file: ../../data/train/jetImage_0_100p_0_10000.h5
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/train/jetImage_2_100p_20000_30000.h5
Could not load file: ../../data/train/jetImage_2_100p_70000_80000.h5
Could not load file: ../../data/train/jetImage_0_100p_40000_50000.h5
Could not load file: ../../data/train/jetImage_2_100p_80000_90000.h5
Could not load file: ../../data/train/jetImage_5_100p_40000_50000.h5
Could not load file: ../../data/train/jetImage_1_100p_50000_60000.h5
Could not load file: ../../data/train/jetImage_0_100p_0_10000.h5
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/test/jetImage_9_100p_60000_70000.h5
Could not load file: ../../data/test/jetImage_8_100p_30000_40000.h5
The base learning rate is 0.4
---------------------
Start epoch 0
---------------------
Current Epoch:  0
Neglect the last epoch so that num samples/batch size = int
Testing
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/train/jetImage_0_100p_50000_60000.h5
Could not load file: ../../data/train/jetImage_1_100p_70000_80000.h5
Could not load file: ../../data/test/jetImage_8_100p_40000_50000.h5
Could not load file: ../../data/test/jetImage_7_100p_60000_70000.h5
Could not load file: ../../data/test/jetImage_9_100p_10000_20000.h5
Could not load file: ../../data/test/jetImage_9_100p_30000_40000.h5
The base learning rate is 0.4
---------------------
Start epoch 0
---------------------
Current Epoch:  0
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
The base learning rate is 0.4
---------------------
Start epoch 0
---------------------
Current Epoch:  0
Neglect the last epoch so that num samples/batch size = int
Testing
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
using quant model
---------------------- Model -------------------------
QThreeLayer(
  (quant_input): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_1): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_1): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_2): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_2): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_3): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_3): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_4): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (act): ReLU()
  (softmax): Softmax(dim=1)
)
------------------------------------------------------
Loading Datasets
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/test/jetImage_7_100p_50000_60000.h5

Dataset loading complete!
The base learning rate is 0.4
---------------------
Start epoch 0
---------------------
Input: tensor([ 0.6205,  0.0679,  0.1854, -0.0143, -0.3667, -0.3111, -1.2395, -0.8182,
        -1.2395, -1.4102, -1.4361, -1.0930, -1.6265, -1.0962,  0.2358, -0.8259],
       device='cuda:0')
Quant Input: tensor([ 0.6207,  0.0672,  0.1861, -0.0141, -0.3674, -0.3111, -1.2399, -0.8177,
        -1.2399, -1.4103, -1.4369, -1.0929, -1.6261, -1.0960,  0.2361, -0.8255],
       device='cuda:0')
Dense 1 Out: tensor([0.0000, 0.0000, 0.0000, 0.6865, 1.1708, 0.7835, 0.0000, 0.0000, 0.9784,
        0.0000, 0.0000, 0.4256, 0.0391, 0.2234, 0.0000, 0.0000, 0.0000, 0.0000,
        0.2315, 0.4835, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7142, 0.0000,
        0.0000, 0.9237, 0.2707, 0.9384, 0.4688, 0.0000, 0.5642, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.2658, 0.5552, 0.3816, 0.3832, 0.0000, 1.2319,
        0.0000, 0.0000, 0.0000, 0.0000, 0.7460, 0.3612, 0.5895, 0.1802, 0.9596,
        0.1109, 0.0000, 0.0000, 0.0049, 0.0000, 0.1688, 0.0000, 0.0000, 0.0000,
        0.0000], device='cuda:0', grad_fn=<SelectBackward0>)
Dense2 Out: tensor([0.0000, 0.3032, 0.0579, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.4558, 0.2105, 0.0423, 0.0000, 0.0000, 0.0000, 0.1811, 0.0498, 0.0147,
        0.0000, 0.0000, 0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0032, 0.0000,
        0.2390, 0.0000, 0.1802, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>)
Dense 3 Out: tensor([0.0947, 0.1295, 0.0000, 0.0078, 0.1008, 0.1016, 0.0000, 0.0639, 0.0000,
        0.0139, 0.0000, 0.0725, 0.0959, 0.0000, 0.0000, 0.0544, 0.0000, 0.0000,
        0.1837, 0.0000, 0.1405, 0.0020, 0.0000, 0.0000, 0.0000, 0.0853, 0.0000,
        0.0346, 0.0288, 0.0000, 0.0000, 0.0139], device='cuda:0',
       grad_fn=<SelectBackward0>)
Dense 4 (Final/Softmax) Out: tensor([0.2095, 0.1921, 0.1863, 0.2093, 0.2028], device='cuda:0',
       grad_fn=<SelectBackward0>)
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
using quant model
---------------------- Model -------------------------
QThreeLayer(
  (quant_input): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_1): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_1): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_2): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_2): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_3): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (quant_act_3): QuantAct(activation_bit=13, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)
  (dense_4): (QuantLinear() weight_bit=10, full_precision_flag=False, quantize_fn=symmetric)
  (act): ReLU()
  (softmax): Softmax(dim=1)
)
------------------------------------------------------
Loading Datasets
Could not load file: ../../data/train/jetImage_7_100p_0_10000.h5
Could not load file: ../../data/test/jetImage_7_100p_50000_60000.h5

Dataset loading complete!
The base learning rate is 0.4
---------------------
Start epoch 0
---------------------
Input: tensor([ 0.9973, -0.5689, -0.9084, -0.7846, -0.5167, -0.5147,  2.1315,  1.5027,
         2.1315,  0.2900, -0.1796, -0.5364,  0.7513,  0.1398, -0.8962, -0.4108],
       device='cuda:0')
Quant Input: tensor([ 0.9970, -0.5684, -0.9077, -0.7842, -0.5163, -0.5148,  2.1308,  1.5029,
         2.1308,  0.2902, -0.1800, -0.5372,  0.7514,  0.1399, -0.8958, -0.4107],
       device='cuda:0')
Dense 1 Out: tensor([0.0000, 0.3837, 0.0000, 0.1782, 0.1818, 1.0580, 0.3664, 1.0635, 0.0000,
        0.2458, 0.8525, 0.3481, 0.0000, 0.0000, 0.2412, 0.0000, 0.0000, 0.0000,
        0.6706, 0.6277, 0.0704, 0.0000, 0.5583, 0.0000, 0.0000, 0.3947, 0.6441,
        0.0000, 0.0000, 1.0937, 0.0000, 0.2056, 0.2513, 0.1069, 0.4824, 1.5478,
        0.0000, 0.0831, 0.0219, 0.0000, 0.0000, 0.0000, 0.4450, 0.0000, 0.4788,
        0.0000, 0.4139, 0.0000, 0.0640, 0.0000, 0.4066, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.5144, 0.0000, 0.0000, 0.0000, 0.9155, 0.0000, 0.0238,
        0.0046], device='cuda:0', grad_fn=<SelectBackward0>)
Dense2 Out: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.3180, 0.2751, 0.0074, 0.2522, 0.0000,
        0.3727, 0.0000, 0.0000, 0.0000, 0.1080, 0.0000, 0.1205, 0.0000, 0.0081,
        0.1826, 0.0000, 0.0000, 0.0000, 0.4477, 0.0000, 0.0421, 0.3291, 0.0026,
        0.2266, 0.0000, 0.2514, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>)
Dense 3 Out: tensor([0.0000, 0.0721, 0.0129, 0.0000, 0.0092, 0.0732, 0.0000, 0.0000, 0.0033,
        0.0000, 0.0674, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0759, 0.0000,
        0.0000, 0.0780, 0.0000, 0.0237, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1309, 0.0000, 0.0924], device='cuda:0',
       grad_fn=<SelectBackward0>)
Dense 4 (Final/Softmax) Out: tensor([0.1928, 0.2008, 0.1986, 0.2004, 0.2073], device='cuda:0',
       grad_fn=<SelectBackward0>)
train_bs 1024
test_bs 128
training_type lr_decay
presplit_train False
train_data_path ../../data/jet_data/train.h5
val_data_bath ../../data/jet_data/val.h5
test_data_bath ../../data/jet_data/test.h5
random_labels False
shuffle_random_data False
num_classes 10
label_corrupt_prob 1.0
random_label_path ../../data/random_labels/random_label.pkl
random_label_path_test ../../data/random_labels/random_label_test.pkl
test_on_noise False
data_subset True
subset 1.0
subset_noisy False
arch JT_10b
different_width False
resnet18_width 64
weight_precision 10
bias_precision 10
act_precision 13
batch_norm False
dropout False
exp_num 5
lr 0.4
epochs 100
weight_decay 0.0005
no_lr_decay False
one_lr_decay True
stop_epoch 100
resume None
lr_decay_epoch [100, 150]
save_early_stop False
min_delta 0
patience 0
l1-enable False
l2-enable False
ignore_incomplete_batch True
only_exploration False
save_final False
save_middle False
save_best True
save_frequency 10
saving_folder ../checkpoint/different_knobs_subset_10/lr_0.4/lr_decay/JT_10b/
file_prefix exp_1
mixup_alpha 16.0
------------------------------------------------------
Experiement: lr_decay training for JT_10b
------------------------------------------------------
using quant model
